{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression - Complete Practical Guide\n",
    "\n",
    "## Business Problem: Predicting House Prices\n",
    "\n",
    "**Scenario:** You work as a Data Scientist at a real estate company. Your manager wants a model that **predicts house prices** based on features like size, bedrooms, age, etc.\n",
    "\n",
    "---\n",
    "\n",
    "### What is Linear Regression?\n",
    "\n",
    "It finds the **best-fit straight line** through your data.\n",
    "\n",
    "- **Simple:** `y = mx + b` (1 feature)\n",
    "- **Multiple:** `y = b0 + b1*x1 + b2*x2 + ... + bn*xn` (many features)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Install & Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this ONCE to install required libraries\n",
    "!pip install numpy pandas matplotlib seaborn scikit-learn -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Data Handling ---\n",
    "import numpy as np                # Math operations on arrays\n",
    "import pandas as pd               # Data tables (like Excel)\n",
    "\n",
    "# --- Visualization ---\n",
    "import matplotlib.pyplot as plt   # Creating charts\n",
    "import seaborn as sns             # Beautiful statistical plots\n",
    "\n",
    "# --- Machine Learning ---\n",
    "from sklearn.model_selection import train_test_split   # Split data\n",
    "from sklearn.linear_model import LinearRegression      # Our model\n",
    "from sklearn.preprocessing import StandardScaler       # Scale features\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"All libraries loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create the Dataset\n",
    "\n",
    "We generate **200 realistic houses** with these features:\n",
    "\n",
    "| Feature | Meaning |\n",
    "|---------|---------|\n",
    "| size_sqft | House size in square feet |\n",
    "| bedrooms | Number of bedrooms |\n",
    "| age_years | How old the house is |\n",
    "| distance_city_km | Distance from city center |\n",
    "| **price_lakhs** | **TARGET - what we predict** |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed for reproducibility (everyone gets same data)\n",
    "np.random.seed(42)\n",
    "n = 200\n",
    "\n",
    "# Generate features\n",
    "size_sqft = np.random.uniform(500, 3500, n)\n",
    "bedrooms = np.clip(np.round(size_sqft / 600 + np.random.normal(0, 0.5, n)), 1, 6)\n",
    "age_years = np.random.uniform(0, 50, n)\n",
    "distance_city_km = np.random.uniform(1, 30, n)\n",
    "\n",
    "# Price formula: bigger=more, older=less, far from city=less, + random noise\n",
    "price_lakhs = (\n",
    "    15\n",
    "    + 0.02 * size_sqft\n",
    "    + 5 * bedrooms\n",
    "    - 0.3 * age_years\n",
    "    - 0.5 * distance_city_km\n",
    "    + np.random.normal(0, 5, n)   # Real-world noise\n",
    ")\n",
    "\n",
    "# Create table\n",
    "df = pd.DataFrame({\n",
    "    'size_sqft': np.round(size_sqft, 1),\n",
    "    'bedrooms': bedrooms.astype(int),\n",
    "    'age_years': np.round(age_years, 1),\n",
    "    'distance_city_km': np.round(distance_city_km, 1),\n",
    "    'price_lakhs': np.round(price_lakhs, 2)\n",
    "})\n",
    "\n",
    "print(f\"Created {len(df)} house records\\n\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Explore the Data (EDA)\n",
    "\n",
    "**Rule:** ALWAYS explore before modeling!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic info\n",
    "print(f\"Shape: {df.shape[0]} rows x {df.shape[1]} columns\")\n",
    "print(f\"\\nMissing values:\\n{df.isnull().sum()}\")\n",
    "print(f\"\\nStatistics:\")\n",
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heatmap - shows how features relate to price\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(df.corr(), annot=True, cmap='RdYlGn', center=0, fmt='.2f', square=True)\n",
    "plt.title('Correlation Matrix', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Values close to +1 = strong positive relation\n",
    "# Values close to -1 = strong negative relation\n",
    "# Values close to  0 = no relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plots: each feature vs price\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "features = ['size_sqft', 'bedrooms', 'age_years', 'distance_city_km']\n",
    "colors = ['#3498db', '#2ecc71', '#e74c3c', '#f39c12']\n",
    "\n",
    "for i, feat in enumerate(features):\n",
    "    ax = axes[i // 2][i % 2]\n",
    "    ax.scatter(df[feat], df['price_lakhs'], alpha=0.5, color=colors[i], edgecolors='black', linewidth=0.5)\n",
    "    ax.set_xlabel(feat)\n",
    "    ax.set_ylabel('Price (Lakhs)')\n",
    "    ax.set_title(f'{feat} vs Price')\n",
    "\n",
    "plt.suptitle('Feature vs Price Relationships', fontsize=15, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# If points form a line-like pattern = Linear Regression will work well!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Prepare Data\n",
    "\n",
    "1. Separate **X** (features) from **y** (target price)\n",
    "2. Split into **80% train** / **20% test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "X = df.drop('price_lakhs', axis=1)   # Everything except price\n",
    "y = df['price_lakhs']                 # Only price\n",
    "\n",
    "# Split: 80% train, 20% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training: {X_train.shape[0]} houses\")\n",
    "print(f\"Testing:  {X_test.shape[0]} houses\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Train the Model\n",
    "\n",
    "`.fit()` finds the best coefficients that minimize prediction errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# What the model learned\n",
    "print(\"LEARNED EQUATION:\")\n",
    "print(f\"Price = {model.intercept_:.2f}\", end=\"\")\n",
    "for feat, coef in zip(X.columns, model.coef_):\n",
    "    sign = \"+\" if coef >= 0 else \"-\"\n",
    "    print(f\" {sign} {abs(coef):.4f} x {feat}\", end=\"\")\n",
    "print()\n",
    "\n",
    "print(\"\\nWhat each coefficient means:\")\n",
    "for feat, coef in zip(X.columns, model.coef_):\n",
    "    effect = \"increases\" if coef > 0 else \"decreases\"\n",
    "    print(f\"  {feat:20s} -> +1 unit {effect} price by {abs(coef):.4f} lakhs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Predict & Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test data (model has NEVER seen these houses)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Side-by-side comparison\n",
    "results = pd.DataFrame({\n",
    "    'Actual': y_test.values,\n",
    "    'Predicted': np.round(y_pred, 2),\n",
    "    'Error': np.round(y_test.values - y_pred, 2)\n",
    "})\n",
    "print(\"Actual vs Predicted (first 10):\")\n",
    "results.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Evaluate the Model\n",
    "\n",
    "| Metric | Meaning | Good Value |\n",
    "|--------|---------|------------|\n",
    "| **R²** | % of variation explained | Closer to 1.0 |\n",
    "| **MAE** | Avg error in lakhs | Lower = better |\n",
    "| **RMSE** | Avg error (penalizes big mistakes) | Lower = better |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2   = r2_score(y_test, y_pred)\n",
    "mae  = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "print(\"MODEL PERFORMANCE\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"  R² Score : {r2:.4f}  ({r2*100:.1f}% explained)\")\n",
    "print(f\"  MAE      : {mae:.2f} lakhs\")\n",
    "print(f\"  RMSE     : {rmse:.2f} lakhs\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "if r2 > 0.85:\n",
    "    print(\"Excellent model!\")\n",
    "elif r2 > 0.7:\n",
    "    print(\"Good model!\")\n",
    "else:\n",
    "    print(\"Needs improvement - try adding more features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Actual vs Predicted plot ---\n",
    "# Perfect predictions would sit exactly on the red dashed line\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_test, y_pred, alpha=0.6, color='#3498db', edgecolors='black', linewidth=0.5)\n",
    "mn, mx = min(y_test.min(), y_pred.min()), max(y_test.max(), y_pred.max())\n",
    "plt.plot([mn, mx], [mn, mx], 'r--', linewidth=2, label='Perfect Prediction Line')\n",
    "plt.xlabel('Actual Price (Lakhs)', fontsize=12)\n",
    "plt.ylabel('Predicted Price (Lakhs)', fontsize=12)\n",
    "plt.title(f'Actual vs Predicted (R² = {r2:.3f})', fontsize=14)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Residual Plots ---\n",
    "# Residual = Actual - Predicted (the error)\n",
    "\n",
    "residuals = y_test - y_pred\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Residuals should be randomly scattered around 0 (no pattern)\n",
    "axes[0].scatter(y_pred, residuals, alpha=0.6, color='#e74c3c', edgecolors='black', linewidth=0.5)\n",
    "axes[0].axhline(y=0, color='black', linestyle='--')\n",
    "axes[0].set_xlabel('Predicted Price')\n",
    "axes[0].set_ylabel('Residual (Error)')\n",
    "axes[0].set_title('Residuals vs Predicted')\n",
    "\n",
    "# Residuals should follow a bell curve centered at 0\n",
    "axes[1].hist(residuals, bins=20, color='#9b59b6', edgecolor='black', alpha=0.7)\n",
    "axes[1].axvline(x=0, color='red', linestyle='--', linewidth=2)\n",
    "axes[1].set_xlabel('Residual (Error)')\n",
    "axes[1].set_ylabel('Count')\n",
    "axes[1].set_title('Residual Distribution')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Feature Importance\n",
    "\n",
    "Which features influence price the most?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale features so coefficients are comparable\n",
    "scaler = StandardScaler()\n",
    "model_s = LinearRegression()\n",
    "model_s.fit(scaler.fit_transform(X_train), y_train)\n",
    "\n",
    "imp = pd.DataFrame({'Feature': X.columns, 'Coefficient': model_s.coef_})\n",
    "imp = imp.sort_values('Coefficient')\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "colors = ['#e74c3c' if c < 0 else '#2ecc71' for c in imp['Coefficient']]\n",
    "plt.barh(imp['Feature'], imp['Coefficient'], color=colors, edgecolor='black')\n",
    "plt.axvline(x=0, color='black', linewidth=0.5)\n",
    "plt.xlabel('Impact on Price')\n",
    "plt.title('Feature Importance (Green=Increases, Red=Decreases Price)', fontsize=13)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Predict on New Houses (Business Use Case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New houses that the company wants to price\n",
    "new_houses = pd.DataFrame({\n",
    "    'size_sqft':        [1200,  2500,   800,  3000],\n",
    "    'bedrooms':         [   2,     4,     1,     5],\n",
    "    'age_years':        [   5,    15,    30,     2],\n",
    "    'distance_city_km': [  10,     5,    20,     3]\n",
    "})\n",
    "\n",
    "new_houses['predicted_price'] = np.round(model.predict(new_houses), 2)\n",
    "\n",
    "print(\"NEW LISTING PRICE PREDICTIONS\")\n",
    "print(\"=\" * 60)\n",
    "for i, row in new_houses.iterrows():\n",
    "    print(f\"House {i+1}: {row['size_sqft']:.0f}sqft, {row['bedrooms']}BHK, \"\n",
    "          f\"{row['age_years']}yrs old, {row['distance_city_km']}km from city\")\n",
    "    print(f\"  --> Predicted Price: {row['predicted_price']:.2f} Lakhs\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Simple Linear Regression (Visual Understanding)\n",
    "\n",
    "Using **only 1 feature** so we can SEE the regression line on a 2D plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple model: only size -> price\n",
    "simple = LinearRegression()\n",
    "simple.fit(df[['size_sqft']], df['price_lakhs'])\n",
    "\n",
    "# Line points\n",
    "x_line = np.linspace(df['size_sqft'].min(), df['size_sqft'].max(), 100).reshape(-1, 1)\n",
    "y_line = simple.predict(x_line)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(df['size_sqft'], df['price_lakhs'], alpha=0.5, color='#3498db',\n",
    "            edgecolors='black', linewidth=0.5, label='Data Points')\n",
    "plt.plot(x_line, y_line, color='red', linewidth=3, label='Best Fit Line')\n",
    "plt.xlabel('House Size (sqft)', fontsize=13)\n",
    "plt.ylabel('Price (Lakhs)', fontsize=13)\n",
    "plt.title('Simple Linear Regression: Size vs Price', fontsize=15)\n",
    "plt.legend(fontsize=11)\n",
    "\n",
    "# Show equation on plot\n",
    "plt.text(0.05, 0.95, f'Price = {simple.coef_[0]:.3f} x Size + {simple.intercept_:.2f}',\n",
    "         transform=plt.gca().transAxes, fontsize=12, va='top',\n",
    "         bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Simple Model R² = {simple.score(df[['size_sqft']], df['price_lakhs']):.4f}\")\n",
    "print(f\"Full Model R²   = {r2:.4f}\")\n",
    "print(\"\\nFull model is better because it uses more information!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Practice Exercises\n",
    "\n",
    "Try these yourself to solidify your understanding!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# EXERCISE 1: Predict YOUR dream house price\n",
    "# ============================================================\n",
    "# Change the values below to your dream house and run the cell!\n",
    "\n",
    "my_house = pd.DataFrame({\n",
    "    'size_sqft':        [1500],     # Change this: house size in sqft\n",
    "    'bedrooms':         [3],        # Change this: number of bedrooms\n",
    "    'age_years':        [10],       # Change this: age of house\n",
    "    'distance_city_km': [8]         # Change this: distance from city\n",
    "})\n",
    "\n",
    "my_price = model.predict(my_house)[0]\n",
    "print(f\"Your dream house predicted price: {my_price:.2f} Lakhs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# EXERCISE 2: What happens if we use only 2 features?\n",
    "# ============================================================\n",
    "# Try: train a model using only size_sqft and bedrooms\n",
    "# Compare R² with the full model\n",
    "\n",
    "X_two = df[['size_sqft', 'bedrooms']]        # Only 2 features\n",
    "y_two = df['price_lakhs']\n",
    "\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X_two, y_two, test_size=0.2, random_state=42)\n",
    "\n",
    "model_two = LinearRegression()\n",
    "model_two.fit(X2_train, y2_train)\n",
    "\n",
    "y2_pred = model_two.predict(X2_test)\n",
    "r2_two = r2_score(y2_test, y2_pred)\n",
    "\n",
    "print(f\"2-feature model R² = {r2_two:.4f}\")\n",
    "print(f\"4-feature model R² = {r2:.4f}\")\n",
    "print(f\"\\nDifference: {(r2 - r2_two)*100:.1f}% -- More features = better predictions!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# EXERCISE 3: Try different train/test split ratios\n",
    "# ============================================================\n",
    "\n",
    "for test_pct in [0.1, 0.2, 0.3, 0.5]:\n",
    "    Xt, Xte, yt, yte = train_test_split(X, y, test_size=test_pct, random_state=42)\n",
    "    m = LinearRegression().fit(Xt, yt)\n",
    "    score = r2_score(yte, m.predict(Xte))\n",
    "    print(f\"Train {(1-test_pct)*100:.0f}% / Test {test_pct*100:.0f}%  ->  R² = {score:.4f}  (train size: {len(Xt)})\")\n",
    "\n",
    "# Notice: too little training data = worse model\n",
    "# 80/20 split is a common good balance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Quick Reference Summary\n",
    "\n",
    "| Step | Code | Purpose |\n",
    "|------|------|---------|\n",
    "| Create model | `model = LinearRegression()` | Initialize |\n",
    "| Train | `model.fit(X_train, y_train)` | Learn patterns |\n",
    "| Predict | `model.predict(X_test)` | Make predictions |\n",
    "| Evaluate | `r2_score(y_test, y_pred)` | Check accuracy |\n",
    "| Coefficients | `model.coef_` | Feature weights |\n",
    "| Intercept | `model.intercept_` | Base value |\n",
    "\n",
    "### When to use Linear Regression:\n",
    "- Predicting a **continuous number** (price, salary, temperature)\n",
    "- Features have **linear relationship** with target\n",
    "- You need an **explainable** model\n",
    "\n",
    "### When NOT to use:\n",
    "- Classification (yes/no) -> use Logistic Regression\n",
    "- Non-linear patterns -> use Decision Trees / Random Forest\n",
    "- Very complex data -> use Neural Networks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
